{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea8e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import torch\n",
    "import os, glob\n",
    "import json\n",
    "from re import finditer\n",
    "import pickle\n",
    "import csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8174e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../output\"\n",
    "out_dir = folder + \"/Ontologies_list\"\n",
    "ontologies_dir = out_dir + \"/json/*\"\n",
    "output_dir = out_dir + \"/pkl_list/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ec04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.load(f\"{folder}/vocab.pt\")\n",
    "vocab_stoi = vocab.get_stoi()\n",
    "vocab_list = set(vocab_stoi.keys())\n",
    "# print(vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f97ed3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_case_split(identifier):\n",
    "    matches = finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
    "    return [m.group(0).lower() for m in matches]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "702cde0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for filename in glob.iglob(ontologies_dir, recursive=True):\n",
    "    if os.path.isfile(filename):\n",
    "        concepts= set()\n",
    "        with open(filename,encoding = \"ISO-8859-1\") as f:\n",
    "            data = json.load(f)\n",
    "            for attribute in data[\"classAttribute\"]:\n",
    "                if \"label\" in attribute and \"IRI-based\" in attribute[\"label\"]:\n",
    "                    concepts.add(\" \".join(camel_case_split(attribute[\"label\"][\"IRI-based\"])))\n",
    "            \n",
    "            name = os.path.basename(filename)\n",
    "            out = output_dir + name.split(\".json\")[0] + \".pkl\"\n",
    "            with open(out,\"wb\") as f: \n",
    "                pickle.dump(concepts,f)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a3531be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_vocab_with_ontologies(concepts, filename):\n",
    "    excluded_from_vocab = set()\n",
    "    excluded_from_vocab1 = set()\n",
    "    \n",
    "    for item in concepts:\n",
    "        elem = item.split(\" \")\n",
    "        elem_len = len(elem)\n",
    "        elem_counter = 0\n",
    "        for indiv in elem:\n",
    "            if indiv in vocab_list:\n",
    "                elem_counter +=1\n",
    "            else:\n",
    "                excluded_from_vocab1.add(indiv)\n",
    "                \n",
    "        if elem_counter != elem_len:\n",
    "            excluded_from_vocab.add(item)\n",
    "    \n",
    "    write_output_to_csv(concepts, True, excluded_from_vocab, filename)\n",
    "    \n",
    "    write_output_to_csv(concepts, False, excluded_from_vocab1, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6ba89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output_to_csv(concepts, all_words, excluded_from_vocab, filename):\n",
    "    out_filename = out_dir + \"/report.csv\"\n",
    "    \n",
    "    with open(out_filename, \"a\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        text = \"Compared with keywords as it is\" if all_words else \"Compared with each word of a particular keyword\"\n",
    "\n",
    "        row = [filename, text , len(vocab_list), len(concepts), len(excluded_from_vocab), str(excluded_from_vocab)]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25377d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Completed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for filename in glob.iglob(output_dir + \"*\", recursive=True):\n",
    "    if os.path.isfile(filename):\n",
    "        concepts= set()\n",
    "        name = os.path.basename(filename)\n",
    "        with open(filename,\"rb\") as f:\n",
    "            concepts = pickle.load(f)\n",
    "            compare_vocab_with_ontologies(concepts, name)\n",
    "            \n",
    "print(\"Task Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e87c2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
